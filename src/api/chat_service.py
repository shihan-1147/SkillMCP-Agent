"""
Chat æœåŠ¡

å¤„ç†èŠå¤©è¯·æ±‚ï¼Œæ•´åˆ Agentã€MCPã€RAG
å¯¹å¤–å±è”½å†…éƒ¨å®ç°ç»†èŠ‚
"""

import time
from contextlib import nullcontext
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

from src.agent.tool_recorder import get_tool_recorder, record_tool_call
from src.agent.tracer import (AgentTracer, TraceEventType, create_tracer,
                              set_tracer)
from src.core.config import get_settings
from src.core.exceptions import AgentException
from src.core.logging import get_logger
from src.core.ollama import get_ollama_client

from .schemas import ChatRequest, ChatResponse, ResponseStatus, StructuredData
from .session import Session, get_session_manager

logger = get_logger("api.chat_service")


class ChatService:
    """
    èŠå¤©æœåŠ¡

    èŒè´£ï¼š
    - æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯
    - ç®¡ç†ä¼šè¯
    - è°ƒç”¨ Agent å¤„ç†è¯·æ±‚
    - æ ¼å¼åŒ–å“åº”

    å‰ç«¯æ— éœ€æ„ŸçŸ¥ MCP / RAG / Agent å†…éƒ¨ç»†èŠ‚
    """

    def __init__(self):
        self.settings = get_settings()
        self._agent = None
        self._mcp = None
        self._rag = None
        self._initialized = False

    async def initialize(self) -> None:
        """åˆå§‹åŒ–æœåŠ¡"""
        if self._initialized:
            return

        logger.info("Initializing ChatService...")

        # åˆå§‹åŒ– MCP ç³»ç»Ÿ
        try:
            from src.mcp import initialize_mcp

            self._mcp = await initialize_mcp()
            logger.info("MCP system initialized")
        except Exception as e:
            logger.warning(f"MCP initialization failed: {e}")

        # åˆå§‹åŒ– RAG ç³»ç»Ÿ
        try:
            from pathlib import Path

            from src.rag import get_rag_pipeline
            from src.rag.embedder import MockEmbedder

            self._rag = get_rag_pipeline()

            # è‡ªåŠ¨åŠ è½½æ–‡æ¡£ç›®å½•
            docs_dir = Path(self.settings.documents_dir)
            if docs_dir.exists():
                await self._rag.load_documents(docs_dir)
                logger.info(f"RAG loaded documents from {docs_dir}")
        except Exception as e:
            logger.warning(f"RAG initialization failed: {e}")

        self._initialized = True
        logger.info("ChatService initialized")

    async def chat(self, request: ChatRequest, debug: bool = False) -> ChatResponse:
        """
        å¤„ç†èŠå¤©è¯·æ±‚

        Args:
            request: èŠå¤©è¯·æ±‚
            debug: æ˜¯å¦è¿”å›è°ƒè¯•ä¿¡æ¯

        Returns:
            èŠå¤©å“åº”
        """
        await self.initialize()

        # åˆ›å»ºè¿½è¸ªå™¨
        tracer = create_tracer(enable_console=True)
        tracer.start(query=request.message[:100])

        # è·å–æˆ–åˆ›å»ºä¼šè¯
        session_manager = get_session_manager()
        session = await session_manager.get_or_create(request.session_id)

        # è®°å½•ç”¨æˆ·æ¶ˆæ¯
        session.add_message("user", request.message)

        logger.info(
            f"Chat request: session={session.session_id}, message={request.message[:50]}..."
        )

        try:
            # å¤„ç†æ¶ˆæ¯
            reply, structured_data, sources, debug_info = await self._process_message(
                message=request.message, session=session, debug=debug, tracer=tracer
            )

            # è®°å½•åŠ©æ‰‹å›å¤
            session.add_message("assistant", reply)

            # ç»“æŸè¿½è¸ª
            tracer.end(success=True, result=reply)

            # æ·»åŠ è¿½è¸ªä¿¡æ¯åˆ°è°ƒè¯•æ•°æ®
            if debug and debug_info:
                debug_info["trace"] = tracer.get_timeline()
                debug_info["tool_calls"] = [t.to_dict() for t in tracer.tool_calls]

            return ChatResponse(
                status=ResponseStatus.SUCCESS,
                message="OK",
                reply=reply,
                session_id=session.session_id,
                structured_data=structured_data,
                sources=sources,
                debug_info=debug_info if debug else None,
            )

        except Exception as e:
            logger.error(f"Chat processing error: {e}")

            # ç»“æŸè¿½è¸ªï¼ˆå¤±è´¥ï¼‰
            tracer.end(success=False, error=str(e))

            # ç”Ÿæˆé”™è¯¯å›å¤
            error_reply = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚"
            session.add_message("assistant", error_reply)

            return ChatResponse(
                status=ResponseStatus.ERROR,
                message=str(e),
                reply=error_reply,
                session_id=session.session_id,
                debug_info=(
                    {"error": str(e), "trace": tracer.get_timeline()} if debug else None
                ),
            )

    async def _process_message(
        self,
        message: str,
        session: Session,
        debug: bool = False,
        tracer: AgentTracer = None,
    ) -> Tuple[
        str, Optional[List[StructuredData]], Optional[List[str]], Optional[Dict]
    ]:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯

        æ ¹æ®æ¶ˆæ¯å†…å®¹è·¯ç”±åˆ°ä¸åŒçš„å¤„ç†æµç¨‹

        Returns:
            (reply, structured_data, sources, debug_info)
        """
        debug_info = {} if debug else None
        structured_data = []
        sources = []
        tool_recorder = get_tool_recorder()

        # è·å–å¯¹è¯å†å²
        history = session.get_history_for_llm(limit=10)

        # åˆ†ææ„å›¾å¹¶è·¯ç”±
        with tracer.trace(TraceEventType.PLANNER_START) if tracer else nullcontext():
            intent = self._analyze_intent(message)
            if tracer:
                tracer.log_intent(intent)

        if debug:
            debug_info["intent"] = intent
            debug_info["history_length"] = len(history)

        # æ ¹æ®æ„å›¾å¤„ç†
        if intent == "weather":
            if tracer:
                tracer.log_skill_selected("weather_skill", "æ£€æµ‹åˆ°å¤©æ°”æŸ¥è¯¢å…³é”®è¯")
            reply, data = await self._handle_weather(
                message, tracer, tool_recorder, session.session_id
            )
            if data:
                structured_data.append(data)
                sources.append("weather_api")

        elif intent == "train":
            if tracer:
                tracer.log_skill_selected("train_skill", "æ£€æµ‹åˆ°ç«è½¦ç¥¨æŸ¥è¯¢å…³é”®è¯")
            reply, data = await self._handle_train(
                message, tracer, tool_recorder, session.session_id
            )
            if data:
                structured_data.append(data)
                sources.append("12306_api")

        elif intent == "knowledge":
            if tracer:
                tracer.log_skill_selected("knowledge_skill", "æ£€æµ‹åˆ°çŸ¥è¯†æŸ¥è¯¢å…³é”®è¯")
            reply, data, rag_sources = await self._handle_knowledge(
                message, tracer, tool_recorder, session.session_id
            )
            if data:
                structured_data.append(data)
            sources.extend(rag_sources)

        else:
            if tracer:
                tracer.log_skill_selected("general_skill", "é€šç”¨å¯¹è¯")
            # é€šç”¨å¯¹è¯
            reply = await self._handle_general(message, history)

        if debug:
            debug_info["structured_data_count"] = len(structured_data)
            debug_info["sources"] = sources

        return (
            reply,
            structured_data if structured_data else None,
            sources if sources else None,
            debug_info,
        )

    def _analyze_intent(self, message: str) -> str:
        """
        åˆ†æç”¨æˆ·æ„å›¾

        ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥ç”¨ LLM åˆ†ç±»
        """
        message_lower = message.lower()

        # å¤©æ°”ç›¸å…³
        weather_keywords = ["å¤©æ°”", "æ°”æ¸©", "ä¸‹é›¨", "æ™´å¤©", "æ¸©åº¦", "ç©¿ä»€ä¹ˆ"]
        if any(kw in message_lower for kw in weather_keywords):
            return "weather"

        # ç«è½¦ç¥¨ç›¸å…³
        train_keywords = ["ç«è½¦", "é«˜é“", "åŠ¨è½¦", "è½¦ç¥¨", "12306", "ç«è½¦ç¥¨"]
        if any(kw in message_lower for kw in train_keywords):
            return "train"

        # çŸ¥è¯†æŸ¥è¯¢
        knowledge_keywords = ["ä»€ä¹ˆæ˜¯", "å¦‚ä½•", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "ä»‹ç»", "è§£é‡Š"]
        if any(kw in message_lower for kw in knowledge_keywords):
            return "knowledge"

        return "general"

    async def _handle_weather(
        self,
        message: str,
        tracer: AgentTracer = None,
        tool_recorder=None,
        session_id: str = None,
    ) -> Tuple[str, Optional[StructuredData]]:
        """å¤„ç†å¤©æ°”æŸ¥è¯¢"""
        # æå–åŸå¸‚
        city = self._extract_city(message) or "åŒ—äº¬"

        try:
            if self._mcp:
                # è®°å½•å·¥å…·è°ƒç”¨å¼€å§‹
                start_time = time.time()
                if tracer:
                    tracer.log_event(
                        TraceEventType.MCP_CALL_START,
                        {"tool": "weather_query", "city": city},
                    )

                result = await self._mcp.client.call_tool(
                    "weather_query", {"city": city, "type": "live"}
                )

                # è®°å½•å·¥å…·è°ƒç”¨ç»“æŸ
                duration_ms = (time.time() - start_time) * 1000
                if tracer:
                    tracer.log_tool_call(
                        tool_name="weather_query",
                        arguments={"city": city, "type": "live"},
                        result=result,
                        success=result.get("success", False),
                        duration_ms=duration_ms,
                    )

                if tool_recorder:
                    tool_recorder.record_call(
                        tool_name="weather_query",
                        arguments={"city": city, "type": "live"},
                        result=result,
                        duration_ms=duration_ms,
                        session_id=session_id,
                        skill_name="weather_skill",
                        user_query=message,
                    )

                if result.get("success"):
                    data = result["data"]

                    # ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤ (é€‚é…çœŸå® API è¿”å›æ ¼å¼)
                    weather = data.get("weather", "æœªçŸ¥")
                    weather_icon = data.get("weather_icon", "ğŸŒ¡ï¸")
                    temperature = data.get("temperature", "N/A")
                    wind_dir = data.get("wind_direction", "")
                    wind_power = data.get("wind_power", "")
                    suggestion = data.get("suggestion", "æš‚æ— å»ºè®®")
                    data_source = data.get("data_source", "")

                    reply_parts = [
                        f"{city}å½“å‰å¤©æ°”{weather} {weather_icon}ï¼Œ",
                        f"æ¸©åº¦{temperature}â„ƒï¼Œ",
                        f"{wind_dir}{wind_power}ã€‚",
                    ]

                    if suggestion:
                        reply_parts.append(f"\n\nğŸ’¡ {suggestion}")

                    if data_source:
                        reply_parts.append(f"\n\nğŸ“Š æ•°æ®æ¥æº: {data_source}")

                    reply = "".join(reply_parts)

                    structured = StructuredData(
                        type="weather",
                        data={
                            "city": city,
                            "weather": weather,
                            "temperature": temperature,
                            "humidity": data.get("humidity", "N/A"),
                            "wind": f"{wind_dir}{wind_power}",
                            "suggestion": suggestion,
                            "data_source": data_source,
                        },
                    )

                    return reply, structured
                else:
                    # API è°ƒç”¨å¤±è´¥ï¼Œè¿”å›çœŸå®çš„é”™è¯¯ä¿¡æ¯
                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                    reply = f"âŒ æ— æ³•è·å–{city}çš„å¤©æ°”ä¿¡æ¯\n\n**åŸå› **: {error_msg}"

                    structured = StructuredData(
                        type="error",
                        data={
                            "error_type": "api_error",
                            "message": error_msg,
                            "city": city,
                        },
                    )

                    return reply, structured

            # Fallback
            return f"æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•è·å–{city}çš„å¤©æ°”ä¿¡æ¯ã€‚", None

        except Exception as e:
            logger.error(f"Weather query error: {e}")
            return f"æŸ¥è¯¢{city}å¤©æ°”æ—¶å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚", None

    async def _handle_train(
        self,
        message: str,
        tracer: AgentTracer = None,
        tool_recorder=None,
        session_id: str = None,
    ) -> Tuple[str, Optional[StructuredData]]:
        """å¤„ç†ç«è½¦ç¥¨æŸ¥è¯¢"""
        # æå–å‡ºå‘åœ°å’Œç›®çš„åœ°
        origin, destination = self._extract_route(message)

        if not origin or not destination:
            return "è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å‡ºå‘åŸå¸‚å’Œç›®çš„åœ°åŸå¸‚ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬åˆ°ä¸Šæµ·çš„é«˜é“ã€‚", None

        try:
            if self._mcp:
                # è·å–æ—¥æœŸ
                start_time = time.time()
                if tracer:
                    tracer.log_event(
                        TraceEventType.MCP_CALL_START, {"tool": "system_time"}
                    )

                date_result = await self._mcp.client.call_tool(
                    "system_time", {"action": "get_current"}
                )

                duration_ms = (time.time() - start_time) * 1000
                if tracer:
                    tracer.log_tool_call(
                        "system_time",
                        {"action": "get_current"},
                        date_result,
                        True,
                        duration_ms=duration_ms,
                    )

                today = date_result["data"]["date"]

                # è§£æç›¸å¯¹æ—¥æœŸ
                if "æ˜å¤©" in message:
                    start_time = time.time()
                    date_result = await self._mcp.client.call_tool(
                        "system_time",
                        {"action": "parse_relative", "relative_expr": "æ˜å¤©"},
                    )
                    duration_ms = (time.time() - start_time) * 1000
                    if tracer:
                        tracer.log_tool_call(
                            "system_time",
                            {"action": "parse_relative"},
                            date_result,
                            True,
                            duration_ms=duration_ms,
                        )
                    today = date_result["data"]["parsed_date"]

                # æŸ¥è¯¢è½¦ç¥¨
                start_time = time.time()
                if tracer:
                    tracer.log_event(
                        TraceEventType.MCP_CALL_START, {"tool": "12306_query"}
                    )

                result = await self._mcp.client.call_tool(
                    "12306_query",
                    {
                        "action": "query_tickets",
                        "origin": origin,
                        "destination": destination,
                        "date": today,
                    },
                )

                duration_ms = (time.time() - start_time) * 1000
                if tracer:
                    tracer.log_tool_call(
                        tool_name="12306_query",
                        arguments={
                            "origin": origin,
                            "destination": destination,
                            "date": today,
                        },
                        result=result,
                        success=result.get("success", False),
                        duration_ms=duration_ms,
                    )

                if tool_recorder:
                    tool_recorder.record_call(
                        tool_name="12306_query",
                        arguments={
                            "origin": origin,
                            "destination": destination,
                            "date": today,
                        },
                        result=result,
                        duration_ms=duration_ms,
                        session_id=session_id,
                        skill_name="train_skill",
                        user_query=message,
                    )

                if result.get("success"):
                    data = result["data"]
                    trains = data["trains"][:5]  # åªå–å‰5ä¸ª

                    # ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤
                    reply_parts = [
                        f"ğŸš„ {origin} â†’ {destination} ({data['date']})",
                        f"å…±æ‰¾åˆ° {data['total']} ä¸ªè½¦æ¬¡ï¼Œä»¥ä¸‹æ˜¯éƒ¨åˆ†ç»“æœï¼š\n",
                    ]

                    for train in trains:
                        seats_info = "ã€".join(
                            f"{k}:{v}" for k, v in train["seats"].items()
                        )
                        reply_parts.append(
                            f"â€¢ {train['train_no']} ({train['train_type']})\n"
                            f"  {train['departure_time']} â†’ {train['arrival_time']} "
                            f"({train['duration']})\n"
                            f"  {seats_info}"
                        )

                    reply = "\n".join(reply_parts)

                    structured = StructuredData(
                        type="train",
                        data={
                            "origin": origin,
                            "destination": destination,
                            "date": data["date"],
                            "total": data["total"],
                            "trains": trains,
                        },
                    )

                    return reply, structured
                else:
                    # API è°ƒç”¨å¤±è´¥ï¼Œè¿”å›çœŸå®çš„é”™è¯¯ä¿¡æ¯
                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                    suggestion = result.get("suggestion", [])
                    query_info = result.get("query_info", {})

                    reply_parts = [
                        f"âŒ æ— æ³•æŸ¥è¯¢ {origin} â†’ {destination} çš„ç«è½¦ç¥¨",
                        f"\n**åŸå› **: {error_msg}",
                        f"\n**æŸ¥è¯¢ä¿¡æ¯**:",
                        f"- å‡ºå‘ç«™: {origin} ({query_info.get('origin_code', 'N/A')})",
                        f"- åˆ°è¾¾ç«™: {destination} ({query_info.get('destination_code', 'N/A')})",
                        f"- æ—¥æœŸ: {query_info.get('date', 'N/A')}",
                    ]

                    if suggestion:
                        reply_parts.append("\n**å»ºè®®**:")
                        for s in suggestion:
                            reply_parts.append(f"- {s}")

                    reply = "\n".join(reply_parts)

                    # è¿”å›ç»“æ„åŒ–é”™è¯¯æ•°æ®
                    structured = StructuredData(
                        type="error",
                        data={
                            "error_type": "api_not_available",
                            "message": error_msg,
                            "query_info": query_info,
                            "suggestion": suggestion,
                        },
                    )

                    return reply, structured

            return f"æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•æŸ¥è¯¢{origin}åˆ°{destination}çš„è½¦ç¥¨ä¿¡æ¯ã€‚", None

        except Exception as e:
            logger.error(f"Train query error: {e}")
            return "æŸ¥è¯¢è½¦ç¥¨æ—¶å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚", None

    async def _handle_knowledge(
        self,
        message: str,
        tracer: AgentTracer = None,
        tool_recorder=None,
        session_id: str = None,
    ) -> Tuple[str, Optional[StructuredData], List[str]]:
        """å¤„ç†çŸ¥è¯†æŸ¥è¯¢ï¼ˆRAGï¼‰"""
        sources = []

        try:
            if self._rag and self._rag._initialized:
                # RAG æ£€ç´¢
                start_time = time.time()
                if tracer:
                    tracer.log_event(
                        TraceEventType.RAG_QUERY_START, {"query": message[:50]}
                    )

                results = await self._rag.retrieve(message, top_k=3)

                duration_ms = (time.time() - start_time) * 1000
                if tracer:
                    tracer.log_rag_query(message, len(results), duration_ms)

                if results:
                    # è·å–ä¸Šä¸‹æ–‡
                    context = self._rag.get_context_for_prompt(results)

                    # æ”¶é›†æ¥æº
                    sources = list(
                        set(r.chunk.metadata.get("title", "unknown") for r in results)
                    )

                    # ç”Ÿæˆå›å¤ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ç”¨ LLMï¼‰
                    reply = self._generate_knowledge_reply(message, results)

                    structured = StructuredData(
                        type="knowledge",
                        data={
                            "query": message,
                            "sources": sources,
                            "context_length": len(context),
                        },
                    )

                    return reply, structured, sources

            # å¦‚æœ RAG ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨ MCP å·¥å…·
            if self._mcp:
                start_time = time.time()
                if tracer:
                    tracer.log_event(
                        TraceEventType.MCP_CALL_START, {"tool": "rag_retriever"}
                    )

                result = await self._mcp.client.call_tool(
                    "rag_retriever", {"query": message, "top_k": 3}
                )

                duration_ms = (time.time() - start_time) * 1000
                if tracer:
                    tracer.log_tool_call(
                        tool_name="rag_retriever",
                        arguments={"query": message, "top_k": 3},
                        result=result,
                        success=result.get("success", False),
                        duration_ms=duration_ms,
                    )

                if tool_recorder:
                    tool_recorder.record_call(
                        tool_name="rag_retriever",
                        arguments={"query": message, "top_k": 3},
                        result=result,
                        duration_ms=duration_ms,
                        session_id=session_id,
                        skill_name="knowledge_skill",
                        user_query=message,
                    )

                if result.get("success") and result["data"]["documents"]:
                    docs = result["data"]["documents"]
                    sources = [doc.get("title", "unknown") for doc in docs]

                    reply = self._generate_knowledge_reply_from_docs(message, docs)

                    return reply, None, sources

            return f"æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ²¡æœ‰æ‰¾åˆ°å…³äºã€Œ{message}ã€çš„ç›¸å…³ä¿¡æ¯ã€‚", None, []

        except Exception as e:
            logger.error(f"Knowledge query error: {e}")
            return "æŸ¥è¯¢çŸ¥è¯†åº“æ—¶å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚", None, []

    async def _handle_general(self, message: str, history: List[Dict[str, str]]) -> str:
        """
        å¤„ç†é€šç”¨å¯¹è¯

        ä½¿ç”¨ Ollama LLM è¿›è¡Œæ™ºèƒ½å›å¤
        """
        try:
            # è·å– Ollama å®¢æˆ·ç«¯
            client = get_ollama_client()

            # æ„å»ºæ¶ˆæ¯å†å²
            messages = []

            # æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰
            system_prompt = (
                "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢å¤©æ°”ã€ç«è½¦ç¥¨ä¿¡æ¯ï¼Œ"
                "æˆ–è€…å›ç­”å„ç§é—®é¢˜ã€‚è¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­æ°”å›å¤ç”¨æˆ·ã€‚"
            )
            messages.append({"role": "system", "content": system_prompt})

            # æ·»åŠ å†å²å¯¹è¯
            for msg in history[-10:]:  # æœ€å¤šä¿ç•™æœ€è¿‘ 10 è½®å¯¹è¯
                messages.append({"role": msg["role"], "content": msg["content"]})

            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": message})

            # è°ƒç”¨ Ollama æ¨¡å‹
            logger.info(f"Calling Ollama model: {self.settings.ollama_model}")
            response = await client.chat(
                messages=messages, temperature=0.7, max_tokens=2048
            )

            # æå–å›å¤å†…å®¹
            if response and response.get("success") and response.get("content"):
                reply = response["content"]
                logger.info(f"Ollama response: {reply[:100]}...")
                return reply
            else:
                error_msg = (
                    response.get("error", "Unknown error")
                    if response
                    else "No response"
                )
                logger.warning(f"Ollama response failed: {error_msg}")
                return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"

        except Exception as e:
            logger.error(f"Ollama chat error: {e}", exc_info=True)
            # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            return (
                "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è¯·ç¡®ä¿ï¼š\n"
                f"1. Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ\n"
                f"2. æ¨¡å‹ {self.settings.ollama_model} å·²ä¸‹è½½\n\n"
                "ä½ å¯ä»¥å°è¯•è¿è¡Œï¼šollama pull qwen3:latest"
            )

    def _extract_city(self, message: str) -> Optional[str]:
        """ä»æ¶ˆæ¯ä¸­æå–åŸå¸‚å"""
        cities = [
            "åŒ—äº¬",
            "ä¸Šæµ·",
            "å¹¿å·",
            "æ·±åœ³",
            "æ­å·",
            "æˆéƒ½",
            "æ­¦æ±‰",
            "è¥¿å®‰",
            "å—äº¬",
            "é‡åº†",
            "å¤©æ´¥",
            "è‹å·",
            "é’å²›",
            "å¦é—¨",
            "å¤§è¿",
            "å“ˆå°”æ»¨",
            "é•¿æ²™",
            "éƒ‘å·",
        ]
        for city in cities:
            if city in message:
                return city
        return None

    def _extract_route(self, message: str) -> Tuple[Optional[str], Optional[str]]:
        """
        ä»æ¶ˆæ¯ä¸­æå–å‡ºå‘åœ°å’Œç›®çš„åœ°

        ä½¿ç”¨å¤šç§æ¨¡å¼åŒ¹é…ï¼Œæ”¯æŒä»»æ„åŸå¸‚å
        """
        import re

        # å…ˆç§»é™¤æ—¶é—´ç›¸å…³çš„è¯
        clean_message = re.sub(
            r"(ä»Šå¤©|æ˜å¤©|åå¤©|å¤§åå¤©|ä¸‹å‘¨[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©]?|è¿™å‘¨[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©]?|å‘¨[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©])",
            "",
            message,
        )

        # æ¨¡å¼1: "ä»Aåˆ°B" æˆ– "Aåˆ°B" æˆ– "Aå»B"
        patterns = [
            r"ä»([^\såˆ°å»å¾€ä»]{2,6}?)(?:åˆ°|å»|å¾€)([^\sçš„é«˜åŠ¨ç«è½¦ç¥¨]{2,6})",
            r"([^\sä»]{2,4}?)(?:åˆ°|å»|å¾€)([^\sçš„é«˜åŠ¨ç«è½¦ç¥¨]{2,4})",
        ]

        for pattern in patterns:
            match = re.search(pattern, clean_message)
            if match:
                origin = match.group(1).strip()
                destination = match.group(2).strip()
                # æ¸…ç†å¤šä½™å­—ç¬¦
                origin = re.sub(r"[ä»å»å¾€åˆ°çš„æŸ¥ä¸€ä¸‹]", "", origin)
                destination = re.sub(r"[ä»å»å¾€åˆ°çš„]", "", destination)
                if (
                    origin
                    and destination
                    and len(origin) >= 2
                    and len(destination) >= 2
                ):
                    return origin, destination

        # æ¨¡å¼2: å·²çŸ¥åŸå¸‚åˆ—è¡¨åŒ¹é…ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
        cities = [
            "åŒ—äº¬",
            "ä¸Šæµ·",
            "å¹¿å·",
            "æ·±åœ³",
            "æ­å·",
            "æˆéƒ½",
            "æ­¦æ±‰",
            "è¥¿å®‰",
            "å—äº¬",
            "é‡åº†",
            "å¤©æ´¥",
            "è‹å·",
            "çŸ³å®¶åº„",
            "éƒ‘å·",
            "é•¿æ²™",
            "æµå—",
            "é’å²›",
            "å¤§è¿",
            "æ²ˆé˜³",
            "å“ˆå°”æ»¨",
            "é•¿æ˜¥",
            "åˆè‚¥",
            "ç¦å·",
            "å¦é—¨",
            "å—æ˜Œ",
            "æ˜†æ˜",
            "è´µé˜³",
            "å—å®",
            "æµ·å£",
            "å…°å·",
            "è¥¿å®",
            "é“¶å·",
            "ä¹Œé²æœ¨é½",
            "å‘¼å’Œæµ©ç‰¹",
            "æ‹‰è¨",
            "å¤ªåŸ",
            "ä¿å®š",
            "å”å±±",
            "ç§¦çš‡å²›",
            "é‚¯éƒ¸",
            "å»ŠåŠ",
            "æ— é”¡",
            "å¸¸å·",
            "å¾å·",
            "æ‰¬å·",
            "æ³°å·",
            "é•‡æ±Ÿ",
            "å®æ³¢",
            "æ¸©å·",
            "å˜‰å…´",
            "ç»å…´",
            "é‡‘å",
            "å°å·",
        ]

        found = []
        for city in cities:
            if city in message:
                pos = message.find(city)
                found.append((city, pos))

        # æŒ‰å‡ºç°ä½ç½®æ’åº
        found.sort(key=lambda x: x[1])

        if len(found) >= 2:
            return found[0][0], found[1][0]
        elif len(found) == 1:
            return found[0][0], None
        return None, None

    def _generate_knowledge_reply(self, query: str, results) -> str:
        """æ ¹æ®æ£€ç´¢ç»“æœç”ŸæˆçŸ¥è¯†å›å¤"""
        if not results:
            return f"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°å…³äºã€Œ{query}ã€çš„ç›¸å…³ä¿¡æ¯ã€‚"

        # ç®€å•æ‹¼æ¥æ£€ç´¢ç»“æœ
        parts = [f"å…³äºã€Œ{query}ã€ï¼Œæˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹ä¿¡æ¯ï¼š\n"]

        for i, result in enumerate(results[:3], 1):
            content = result.chunk.content[:200]
            title = result.chunk.metadata.get("title", "")
            parts.append(f"**{i}. {title}**\n{content}...\n")

        return "\n".join(parts)

    def _generate_knowledge_reply_from_docs(self, query: str, docs: List[Dict]) -> str:
        """æ ¹æ®æ–‡æ¡£åˆ—è¡¨ç”ŸæˆçŸ¥è¯†å›å¤"""
        if not docs:
            return f"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°å…³äºã€Œ{query}ã€çš„ç›¸å…³ä¿¡æ¯ã€‚"

        parts = [f"å…³äºã€Œ{query}ã€ï¼Œæˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹ä¿¡æ¯ï¼š\n"]

        for i, doc in enumerate(docs[:3], 1):
            content = doc.get("content", "")[:200]
            title = doc.get("title", "")
            parts.append(f"**{i}. {title}**\n{content}...\n")

        return "\n".join(parts)


# å…¨å±€æœåŠ¡å®ä¾‹
_chat_service: Optional[ChatService] = None


def get_chat_service() -> ChatService:
    """è·å–å…¨å±€èŠå¤©æœåŠ¡"""
    global _chat_service
    if _chat_service is None:
        _chat_service = ChatService()
    return _chat_service
